{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "To run the example, a file named `secret.py` must be created in the notebooks\n",
    "folder with the following content:\n",
    "\n",
    "```python\n",
    "# Configuration settings\n",
    "\n",
    "# SLIPO workbench installation\n",
    "BASE_URL = 'https://app.dev.slipo.eu'\n",
    "\n",
    "# SLIPO API key\n",
    "API_KEY = ''\n",
    "```\n",
    "\n",
    "The `API_KEY` value must be set to a valid SLIPO Application Key. The file must be imported before creating a new context:\n",
    "\n",
    "```python\n",
    "from secret import BASE_URL, API_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new context\n",
    "from slipoframes.context import SlipoContext\n",
    "\n",
    "from secret import BASE_URL, API_KEY\n",
    "\n",
    "ctx = SlipoContext(\n",
    "    base_url = BASE_URL,\n",
    "    requires_ssl = False,\n",
    "    api_key = API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform operation\n",
    "\n",
    "Next we are going to:\n",
    "\n",
    "* Upload the files `DKV_Fuel_Berlin.csv` and `OSM_Fuel_Berlin.csv` from the local folder `datasets` to the remote folder `notebooks/datasets`. The remote folder will be created automatically if not already exists. The option `overwrite` is also set to `True` to overwrite any existing files.\n",
    "* Upload the contents of folder `config` from the local file system to the remote folder `notebooks/config`.\n",
    "* Execute two transform operations to convert the `CSV` data to `N-Triples`.\n",
    "* Check the status of each operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload file DKV_Berlin.csv\n",
    "ctx.file_upload('./datasets/DKV_Fuel_Berlin.csv', 'notebooks/datasets/DKV_Fuel_Berlin.csv', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload file DKV_Berlin.csv\n",
    "ctx.file_upload('./datasets/OSM_Fuel_Berlin.csv', 'notebooks/datasets/OSM_Fuel_Berlin.csv', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload all files in the config folder\n",
    "ctx.file_upload('./config', 'notebooks/config', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse remote user file system\n",
    "df_files = ctx.file_browse(sort_col='size', format_size=True, sort_asc=False)\n",
    "\n",
    "df_files[df_files['path'].str.startswith(\"notebooks\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DKV_Fuel_Berlin.csv file to N-Triples\n",
    "transform1 = ctx.transform_csv(\n",
    "    'notebooks/datasets/DKV_Fuel_Berlin.csv',\n",
    "    attrCategory='all_tags',\n",
    "    attrKey='ID',\n",
    "    attrName='name',\n",
    "    attrX='lon',\n",
    "    attrY='lat',\n",
    "    delimiter=';',\n",
    "    featureSource='DKV',\n",
    "    quote='',\n",
    "    mappingSpec='notebooks/config/DKV_Fuel_Berlin_slipo_mappings.yml',\n",
    "    classificationSpec='notebooks/config/DKV_POI_sample_classification.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert OSM_Fuel_Berlin.csv file to N-Triples\n",
    "transform2 = ctx.transform_csv(\n",
    "    'notebooks/datasets/OSM_Fuel_Berlin.csv',\n",
    "    attrCategory='type',\n",
    "    attrGeometry='wkt',\n",
    "    attrKey='osm_id',\n",
    "    attrName='name',\n",
    "    attrX='lon',\n",
    "    attrY='lat',\n",
    "    delimiter='|',\n",
    "    featureSource='OpenStreetMap',\n",
    "    profile='OSM_Europe',\n",
    "    quote='',\n",
    "    mappingSpec='notebooks/config/OSM_Fuel_Berlin_slipo_mappings.yml',\n",
    "    classificationSpec='notebooks/config/OSM_POI_sample_classification.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check process status for transform operations\n",
    "transform1 = ctx.process_status(transform1)\n",
    "transform2 = ctx.process_status(transform2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interlink operation\n",
    "\n",
    "Execute an interlink operation on the RDF datasets generated by the previous two transformation operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interlink1 = ctx.interlink(\n",
    "    'SLIPO_equiMatchByNameAndDistance',\n",
    "    left=transform1.output(),\n",
    "    right=transform2.output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check process status for interlink operation\n",
    "interlink1 = ctx.process_status(interlink1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuse Operation\n",
    "\n",
    "Fuse the two RDF datasets generated by operations `transform1` and `transform2` using the links from operation `interlink`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse1 = ctx.fuse(\n",
    "    'SLIPO_default_abMode',\n",
    "    left=transform1.output(),\n",
    "    right=transform2.output(),\n",
    "    links=interlink1.output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check process status for fuse operation\n",
    "fuse1 = ctx.process_status(fuse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrich Operation\n",
    "\n",
    "Enrich the fused RDF dataset from operation `fuse1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich1 = ctx.enrich(\n",
    "    'SLIPO_TomTom_Bucharest',\n",
    "    source=fuse1.output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check process status for enrich operation\n",
    "enrich1 = ctx.process_status(enrich1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Operation\n",
    "\n",
    "Export the enriched RDF dataset to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export1 = ctx.export_csv(\n",
    "    'SLIPO_default',\n",
    "    enrich1.output(),\n",
    "    delimiter='|',\n",
    "    quote='\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check process status for export operation\n",
    "export1 = ctx.process_status(export1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy output file to local file system\n",
    "ctx.process_file_download(export1.output(), target='./output/exported-data.zip', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute an existing workflow\n",
    "\n",
    "Run a prespecified data integration workflow that involves all stages (transformation, interlinking, fusion, enrichment, export).\n",
    "\n",
    "Identify the workflow, its various versions and their executions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = ctx.process_query(\n",
    "    'Integrate OSM & DKV data in Berlin (updated)',\n",
    "    0,\n",
    "    10\n",
    ")\n",
    "\n",
    "processes[['Id','Name','Executed On','Version']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a new version of this workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.process_start(352, 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the status of this workflow execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1 = ctx.process_status(352, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render this workflow as a graph with all its components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.process_render(workflow1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POI Data Analytics\n",
    "\n",
    "Once integrated POI data has been saved locally, analysis can be perfomed using\n",
    "tools like pandas DataFrames, geopanadas GeoDataFrames or other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip exported CSV file with the results of data integration\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('./output/exported-data.zip','r') as zip_ref:\n",
    "    zip_ref.extractall(\"./output/\")\n",
    "    \n",
    "os.rename('./output/points.csv', './output/Fuel_Berlin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data in a DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "pois = pd.read_csv('./output/Fuel_Berlin.csv', delimiter='|', error_bad_lines=False)\n",
    "\n",
    "# Geometries in the exported CSV file are listed in Extended Well-Known Text (EWKT)\n",
    "# Since shapely does not support EWKT, update the geometry by removing the SRID value from EWKT\n",
    "pois['the_geom'] = pois['the_geom'].apply(lambda x: x.split(';')[1])\n",
    "\n",
    "pois.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataFrame\n",
    "import geopandas\n",
    "from shapely import wkt\n",
    "\n",
    "pois['the_geom'] = pois['the_geom'].apply(wkt.loads)\n",
    "\n",
    "gdf = geopandas.GeoDataFrame(pois, geometry='the_geom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the location of the exported POIs on a simple plot using matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# Restrict focus to Germany:\n",
    "ax = world[world.name == 'Germany'].plot(\n",
    "    color='white', edgecolor='black')\n",
    "\n",
    "# Plot the contents of the GeoDataFrame in blue dots:\n",
    "gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POI Data Analytics using LOCI\n",
    "\n",
    "Perform spatial analytics over the integrated POI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCI dependencies:\n",
    "import loci as lc\n",
    "from loci import io\n",
    "from loci import analytics\n",
    "from loci import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the integrated POI dataset:\n",
    "pois = lc.io.read_poi_csv(input_file='./output/Fuel_Berlin.csv',\n",
    "                       col_id='id',\n",
    "                       col_name='uri',\n",
    "                       col_lon='lon',\n",
    "                       col_lat='lat',\n",
    "                       col_kwds='name',\n",
    "                       col_sep='|',\n",
    "                       kwds_sep=',',\n",
    "                       source_crs='EPSG:4326',\n",
    "                       target_crs='EPSG:4326',\n",
    "                       keep_other_cols=False)\n",
    "\n",
    "# Turn all names in uppercase characters to facilitate comparison:\n",
    "pois['name'] = pois['name'].apply(lambda x: [element.upper() for element in x])\n",
    "\n",
    "pois.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize the name of the various brands as keywords for spatial analytics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois.rename(columns={'name': 'kwds'}, inplace=True)\n",
    "pois.rename(columns={'uri': 'name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw locations on map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = lc.plots.map_points(pois, show_bbox=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics on the number of fuel stations per brand name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = lc.analytics.kwds_freq(pois)\n",
    "kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chart showing fuel stations per brand name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.plots.barchart(kf, plot_title='Top Keywords', x_axis_label='Keywords', y_axis_label='Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word cloud of the various brands in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.plots.plot_wordcloud(pois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap of the fuel stations belonging to a particular brand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_filtered = lc.analytics.filter_by_kwd(pois, 'TOTAL')\n",
    "lc.plots.heatmap(pois_filtered, radius=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
